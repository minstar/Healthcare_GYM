# ============================================================================
# Autonomous Healthcare AI GYM -- Pure RL (GRPO) Continuous Training
# ============================================================================
#
# 8x A100 80GB GPUs, running 24/7
# VL (Vision-Language) models only — full modality coverage
#
# Training Philosophy: PURE RL, NO SFT
# ─────────────────────────────────────
# Pre-trained 7-10B VL models already possess medical knowledge.
# Instead of memorizing answers via SFT, each agent improves through:
#   1. Multi-turn GRPO with Environment-in-the-Loop
#   2. 5D Adaptive Reward: accuracy + format + process + safety + coherence
#   3. Benchmark-Guided Reward Weights: external benchmark results
#      (MedQA, MMLU, VQA) dynamically adjust reward weights so the
#      model self-corrects its weaknesses through RL exploration.
#
# Learning Cycle (per agent, per cycle):
#   Phase 1: REFLECT — analyze recent performance from SharedLogbook
#   Phase 2: BENCHMARK — evaluate on 14+ external benchmarks (every N cycles)
#   Phase 3: CHOOSE — select domain + motivation via intrinsic strategy
#   Phase 4: GRPO TRAIN — multi-turn environment interaction with 5D reward
#   Phase 5: RECORD — log results to SharedLogbook
#
# W&B: All runs logged to project "pt2-minstar-gym-rl"
#
# Models (all VL-capable, <10B):
#   - LingShu-7B (Qwen2.5-VL based, medical VL)  x3 agents
#   - Step3-VL-10B (Step3 VL, multi-modal)        x3 agents
#   - Qwen2.5-VL-7B-Instruct (general VL)         x2 agents
#
# Usage:
#   python scripts/run_autonomous_gym.py --config configs/autonomous_gym.yaml
#
# ============================================================================

# --- GYM Configuration ---
gym:
  num_gpus: 8
  gpu_ids: [0, 1, 2, 3, 4, 5, 6, 7]

  # ALL domains -- VL models handle everything including visual_diagnosis & radiology_report
  available_domains:
    - clinical_diagnosis
    - drug_interaction
    - ehr_management
    - medical_qa
    - triage_emergency
    - cross_domain
    - psychiatry
    - obstetrics
    - visual_diagnosis
    - radiology_report

  # Safety guardrails
  safety_score_floor: 0.20
  max_consecutive_failures: 8
  cooldown_seconds: 120

  # Scheduling
  max_queue_size: 50
  idle_check_interval: 10.0

  # Logging & W&B
  log_dir: "logs/autonomous_gym"
  logbook_dir: "logs/shared_logbook"
  wandb_project: "pt2-minstar-gym-rl"

  continuous: true

# --- External Benchmark Evaluation ---
# 14+ benchmarks: MedQA, MedMCQA, 6x MMLU, 6x VQA, MedLFQA, EHR
# Runs every N cycles per agent. Set 0 to disable.
benchmark:
  every_n_cycles: 3             # Run external benchmarks every 3rd cycle
  max_samples: 0                # 0 = full benchmark

# --- Agent Configurations ---
# 8 agents = 8 GPUs, ALL vision-language capable
#
# Model lineup:
#   LingShu-7B          (3 agents) — medical VL specialist
#   Step3-VL-10B        (3 agents) — strong multi-modal reasoning
#   Qwen2.5-VL-7B-Inst (2 agents) — general VL with instruction following
#
agents:

  # ===== LingShu-7B VL Agents (Medical VL Specialist) =====

  # Agent 1: LingShu Weakness Fixer — aggressive weakness targeting
  - agent_id: "lingshu_weakness_fixer"
    model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Lingshu-7B"
    base_model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Lingshu-7B"
    backend: "transformers"
    gpus_for_eval: 1
    gpus_for_train: 1
    curiosity_weight: 0.10
    weakness_weight: 0.40
    peer_learning_weight: 0.15
    diversity_weight: 0.10
    mastery_push_weight: 0.15
    safety_weight: 0.10
    max_turns: 15
    eval_tasks_per_domain: 15
    training_epochs: 2
    learning_rate: 0.00002
    quality_threshold: 0.4
    mastery_threshold: 0.90
    output_dir: "checkpoints/autonomous/lingshu_weakness_fixer"
    log_dir: "logs/autonomous/lingshu_weakness_fixer"

  # Agent 2: LingShu Safety — healthcare safety is #1 priority
  - agent_id: "lingshu_safety"
    model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Lingshu-7B"
    base_model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Lingshu-7B"
    backend: "transformers"
    gpus_for_eval: 1
    gpus_for_train: 1
    curiosity_weight: 0.05
    weakness_weight: 0.25
    peer_learning_weight: 0.15
    diversity_weight: 0.10
    mastery_push_weight: 0.10
    safety_weight: 0.35
    max_turns: 20
    eval_tasks_per_domain: 20
    training_epochs: 3
    learning_rate: 0.00001
    quality_threshold: 0.50
    mastery_threshold: 0.90
    output_dir: "checkpoints/autonomous/lingshu_safety"
    log_dir: "logs/autonomous/lingshu_safety"

  # Agent 3: LingShu Mastery — push near-conquered domains over the line
  - agent_id: "lingshu_mastery"
    model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Lingshu-7B"
    base_model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Lingshu-7B"
    backend: "transformers"
    gpus_for_eval: 1
    gpus_for_train: 1
    curiosity_weight: 0.05
    weakness_weight: 0.20
    peer_learning_weight: 0.20
    diversity_weight: 0.10
    mastery_push_weight: 0.35
    safety_weight: 0.10
    max_turns: 15
    eval_tasks_per_domain: 18
    training_epochs: 2
    learning_rate: 0.00001
    quality_threshold: 0.50
    mastery_threshold: 0.90
    output_dir: "checkpoints/autonomous/lingshu_mastery"
    log_dir: "logs/autonomous/lingshu_mastery"

  # ===== Step3-VL-10B Agents (Strong Multi-Modal Reasoning) =====

  # Agent 4: Step3 Explorer — high curiosity, explores new domains
  - agent_id: "step3vl_explorer"
    model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Step3-VL-10B"
    base_model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Step3-VL-10B"
    backend: "transformers"
    gpus_for_eval: 1
    gpus_for_train: 1
    curiosity_weight: 0.30
    weakness_weight: 0.15
    peer_learning_weight: 0.15
    diversity_weight: 0.25
    mastery_push_weight: 0.10
    safety_weight: 0.05
    max_turns: 15
    eval_tasks_per_domain: 12
    training_epochs: 2
    learning_rate: 0.00002
    quality_threshold: 0.35
    mastery_threshold: 0.90
    output_dir: "checkpoints/autonomous/step3vl_explorer"
    log_dir: "logs/autonomous/step3vl_explorer"

  # Agent 5: Step3 Peer Learner — studies what other agents do well
  - agent_id: "step3vl_peer_learner"
    model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Step3-VL-10B"
    base_model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Step3-VL-10B"
    backend: "transformers"
    gpus_for_eval: 1
    gpus_for_train: 1
    curiosity_weight: 0.10
    weakness_weight: 0.25
    peer_learning_weight: 0.30
    diversity_weight: 0.15
    mastery_push_weight: 0.10
    safety_weight: 0.10
    max_turns: 15
    eval_tasks_per_domain: 15
    training_epochs: 3
    learning_rate: 0.000015
    quality_threshold: 0.45
    mastery_threshold: 0.90
    output_dir: "checkpoints/autonomous/step3vl_peer_learner"
    log_dir: "logs/autonomous/step3vl_peer_learner"

  # Agent 6: Step3 Generalist — balanced approach across all domains
  - agent_id: "step3vl_generalist"
    model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Step3-VL-10B"
    base_model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Step3-VL-10B"
    backend: "transformers"
    gpus_for_eval: 1
    gpus_for_train: 1
    curiosity_weight: 0.17
    weakness_weight: 0.22
    peer_learning_weight: 0.18
    diversity_weight: 0.17
    mastery_push_weight: 0.13
    safety_weight: 0.13
    max_turns: 15
    eval_tasks_per_domain: 15
    training_epochs: 2
    learning_rate: 0.00002
    quality_threshold: 0.45
    mastery_threshold: 0.90
    output_dir: "checkpoints/autonomous/step3vl_generalist"
    log_dir: "logs/autonomous/step3vl_generalist"

  # ===== Qwen2.5-VL-7B-Instruct Agents (General VL + Instruction) =====

  # Agent 7: Qwen VL Weakness Fixer — fixes weak spots with good instruction following
  - agent_id: "qwen25vl_weakness_fixer"
    model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Qwen2.5-VL-7B-Instruct"
    base_model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Qwen2.5-VL-7B-Instruct"
    backend: "transformers"
    gpus_for_eval: 1
    gpus_for_train: 1
    curiosity_weight: 0.10
    weakness_weight: 0.35
    peer_learning_weight: 0.20
    diversity_weight: 0.10
    mastery_push_weight: 0.15
    safety_weight: 0.10
    max_turns: 15
    eval_tasks_per_domain: 15
    training_epochs: 2
    learning_rate: 0.00002
    quality_threshold: 0.4
    mastery_threshold: 0.90
    output_dir: "checkpoints/autonomous/qwen25vl_weakness_fixer"
    log_dir: "logs/autonomous/qwen25vl_weakness_fixer"

  # Agent 8: Qwen VL Safety — safety-focused with strong instruction compliance
  - agent_id: "qwen25vl_safety"
    model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Qwen2.5-VL-7B-Instruct"
    base_model_path: "/data/project/private/minstar/workspace/BIOAgents/checkpoints/models/Qwen2.5-VL-7B-Instruct"
    backend: "transformers"
    gpus_for_eval: 1
    gpus_for_train: 1
    curiosity_weight: 0.05
    weakness_weight: 0.20
    peer_learning_weight: 0.15
    diversity_weight: 0.10
    mastery_push_weight: 0.10
    safety_weight: 0.40
    max_turns: 20
    eval_tasks_per_domain: 20
    training_epochs: 3
    learning_rate: 0.00001
    quality_threshold: 0.55
    mastery_threshold: 0.90
    output_dir: "checkpoints/autonomous/qwen25vl_safety"
    log_dir: "logs/autonomous/qwen25vl_safety"
